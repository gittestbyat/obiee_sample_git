<?xml version="1.0" encoding="utf-8"?>
<sawd:dashboardPage xmlns:sawd="com.siebel.analytics.web/dashboard/v1.1" xmlVersion="200810300" isEmpty="false" xmlns:saw="com.siebel.analytics.web/report/v1.1" duid="fihoad5dcjb1q4lc" xmlns:xsd="http://www.w3.org/2001/XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"><sawd:dashboardColumn name="Column 2" frozen="false" canFreeze="true" duid="68o5m70k1lsusma8" layoutType="bestFit"><sawd:dashboardSection name="Section 2" duid="8bv4aun7up81lqld" showSectionTitle="true" collapsible="true" showHeading="false" layoutType="bestFit">
			<saw:caption captionID="kcap12832459_2462">
				<saw:text>Page Information (click to collapse or expand)</saw:text>
			</saw:caption>
			<saw:displayFormat>
				<saw:formatSpec borderPosition="all" paddingLeft="0" paddingRight="0" paddingTop="0" paddingBottom="0" wrapText="true" backgroundColor="#F9F9F4" borderColor="#EEEEEE"/>
			</saw:displayFormat>
			<sawd:sectionHeading>
				<saw:displayFormat>
					<saw:formatSpec fontColor="#666699" wrapText="true" fontStyle="italic" fontSize="12" fontFamily="Arial"/>
				</saw:displayFormat>
			</sawd:sectionHeading>
			
		<sawd:htmlView name="HTML 2" duid="0oaouic28aft8dk3">
				<sawd:HTML fmt="html" captionID="kcap12832459_2467">&lt;font style=&quot;font:12px arial&quot;&gt; &lt;img src=&quot;res/sk_blafp/common/rightarrow.gif&quot; /&gt;
&lt;b&gt; Description :&lt;/b&gt; Following script is a simple example of executing map reduce jobs via ORCH. It can be executed from a R command line in SampleApp image. [br/]
MapReduce, the heart of Hadoop, is a programming framework that enables massive scalability across servers using data stored in the Hadoop Distributed File System (HDFS). [br/]
The Oracle R Connector for Hadoop (ORCH) provides access to a Hadoop cluster from R, enabling manipulation of HDFS-resident data and the execution of MapReduce jobs. [br/]

&lt;/font&gt;</sawd:HTML>
			</sawd:htmlView></sawd:dashboardSection></sawd:dashboardColumn><sawd:dashboardColumn name="Column 1" canFreeze="false" duid="7m6qn254nucu9jv8" layoutType="bestFit" break="column" frozen="false"><sawd:dashboardSection layoutType="bestFit" name="Section 1" collapsible="false" duid="6hsn9ba8s98i4v2p" showSectionTitle="false"><saw:displayFormat><saw:formatSpec borderPosition="none" wrapText="true" borderColor="#999999" paddingRight="6"/></saw:displayFormat><sawd:htmlView name="HTML 0" duid="mdrtoncb213lmmnm"><sawd:HTML fmt="html">&lt;pre&gt;
# Example script for executing map reduce jobs
# Open a R terminal on SampleApp env and execute the following 

library(ORCH)
mg.dfs &lt;- hdfs.attach(&quot;/user/oracle/moviework/OAA/purchased_movieid_by_genreid&quot;)
#mg.dfs
#hdfs.describe(mg.dfs)

# Count the number of records ( nrow(vals) ) in each Genre (val$GENREID)
orch.dryrun(F)
res.cluster &lt;- NULL
res.cluster &lt;- hadoop.run( 
  mg.dfs, 
  mapper = function(key, val) { 
    orch.keyvals(val$GENREID, rep(1, nrow(val)))  
  }, 
  reducer = function(key, vals) { 
    count &lt;- nrow(vals) 
    orch.keyval(NULL, key, count) 
  } ,
  config = 
    new(&quot;mapred.config&quot;,
        map.output    = data.frame(key=0, val=0),
        reduce.output = data.frame(key=NA, GENREID=0, COUNT=0))
) 
# Get result and join to get genre names
gn.dfs &lt;- hdfs.attach(&quot;/user/oracle/moviework/OAA/genre_names&quot;)
gn.dat &lt;- hdfs.get(gn.dfs)
res &lt;- merge(gn.dat,hdfs.get(res.cluster))

# Order by count and subset cols to name and count 
res &lt;- res[order(-res[,3]),c(2,3)]

# Return results to OBIEE as an image
library(gplots)
l1 &lt;- paste(capture.output(print(res, row.names = FALSE)))
output &lt;- c(l1)
textplot(output,halign=&quot;center&quot;,valign=&quot;top&quot;, mar=c(2, 2, 3, 2))

# Writes the Title of the output
title(&quot;Map-Reduce Computation\nNo of Purchased Movies per Genre&quot;)

&lt;/pre&gt;</sawd:HTML></sawd:htmlView></sawd:dashboardSection></sawd:dashboardColumn></sawd:dashboardPage>